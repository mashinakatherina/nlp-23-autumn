{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_1 = pd.read_csv(f\"../assets/annotated-corpus/train/1_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "train_2 = pd.read_csv(f\"../assets/annotated-corpus/train/2_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "train_3 = pd.read_csv(f\"../assets/annotated-corpus/train/3_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "train_4 = pd.read_csv(f\"../assets/annotated-corpus/train/4_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "\n",
    "test_1 = pd.read_csv(f\"../assets/annotated-corpus/test/1_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "test_2 = pd.read_csv(f\"../assets/annotated-corpus/test/2_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "test_3 = pd.read_csv(f\"../assets/annotated-corpus/test/3_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n",
    "test_4 = pd.read_csv(f\"../assets/annotated-corpus/test/4_emb.tsv\",delimiter='\\t',header=None).values[:,1:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.row_stack((train_1,train_2,train_3,train_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.row_stack((test_1,test_2,test_3,test_4))\n",
    "\n",
    "y_test1=np.zeros((test_1.shape[0],1))\n",
    "y_test2=np.ones((test_2.shape[0],1))\n",
    "y_test3=np.ones((test_3.shape[0],1))*2\n",
    "y_test4=np.ones((test_4.shape[0],1))*3\n",
    "y_test = np.row_stack((y_test1,y_test2,y_test3,y_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.zeros((train_1.shape[0],1))\n",
    "y2=np.ones((train_2.shape[0],1))\n",
    "y3=np.ones((train_3.shape[0],1))*2\n",
    "y4=np.ones((train_4.shape[0],1))*3\n",
    "y = np.row_stack((y1,y2,y3,y4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(y_true, y_pred, num_classes):\n",
    "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
    "\n",
    "    for true_label, pred_label in zip(y_true, y_pred):\n",
    "        cm[int(true_label)][int(pred_label)] += 1\n",
    "\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def calculate_metrics(confusion_matrix):\n",
    "    num_classes = confusion_matrix.shape[0]\n",
    "    accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "    \n",
    "    precision = np.zeros(num_classes, dtype=np.float32)\n",
    "    recall = np.zeros(num_classes, dtype=np.float32)\n",
    "    f1_score = np.zeros(num_classes, dtype=np.float32)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        true_positive = confusion_matrix[i, i]\n",
    "        false_positive = np.sum(confusion_matrix[:, i]) - true_positive\n",
    "        false_negative = np.sum(confusion_matrix[i, :]) - true_positive\n",
    "\n",
    "        precision[i] = true_positive / (true_positive + false_positive) if (true_positive + false_positive) != 0 else 0\n",
    "        recall[i] = true_positive / (true_positive + false_negative) if (true_positive + false_negative) != 0 else 0\n",
    "\n",
    "        f1_score[i] = 2 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if (precision[i] + recall[i]) != 0 else 0\n",
    "\n",
    "    return [accuracy, mean(precision), mean(recall), mean(f1_score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "all_tests = []\n",
    "from sklearn import svm\n",
    "for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "    for clf_type in [\"ovr\",\"ovo\"]:\n",
    "        for iter_num in [100,500,1000]:\n",
    "            name = f\"{kernel}_{clf_type}_{iter_num}\"\n",
    "            start = timer()\n",
    "            if clf_type==\"ovr\":\n",
    "                clf = OneVsRestClassifier(svm.SVC(kernel=kernel,max_iter=iter_num),n_jobs=-1)\n",
    "            else:\n",
    "                clf = svm.SVC(kernel=kernel,max_iter=iter_num)\n",
    "            clf.fit(X, y.ravel())\n",
    "            end = timer()\n",
    "            test = clf.predict(X_test)\n",
    "            cm = confusion_matrix(y_test.ravel(),test,4)\n",
    "            test_res = calculate_metrics(cm)\n",
    "            test_res.append(end - start)\n",
    "            print((name,test_res))\n",
    "            all_tests.append((name,test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Given data\n",
    "data = all_tests\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data, columns=['Model', 'Metrics'])\n",
    "df = pd.concat([df, pd.DataFrame(df['Metrics'].to_list(), columns=['accuracy', 'precision', 'recall', 'F1', 'Time'])], axis=1)\n",
    "\n",
    "# Melt the DataFrame for better plotting with seaborn\n",
    "df_metrics_melted = pd.melt(df, id_vars=['Model'], value_vars=['accuracy', 'precision', 'recall', 'F1'], var_name='Metric', value_name='Value')\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the bar plot for metrics\n",
    "plt.figure(figsize=(40, 12))\n",
    "ax1 = sns.barplot(x='Model', y='Value', hue='Metric', data=df_metrics_melted, palette='viridis')\n",
    "plt.title('Bar Plot for Metrics by Model (excluding Time)')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "# Plot the bar plot for time separately\n",
    "df_time = df[['Model', 'Time']]\n",
    "plt.figure(figsize=(42, 12))\n",
    "ax2 = sns.barplot(x='Model', y='Time', data=df_time, color='orange')\n",
    "plt.title('Bar Plot for Time by Model')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Time (seconds)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel=\"rbf\",max_iter=5000)\n",
    "clf.fit(X, y.ravel()) \n",
    "test = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test.ravel(),test,4) \n",
    "test_res = calculate_metrics(cm)\n",
    "print(test_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "all_tests = []\n",
    "from sklearn import svm\n",
    "results = []\n",
    "for num_comp in [256,128,64,32,16,8,4,2]:\n",
    "    for whitten in [True,False]:\n",
    "        name = f\"{num_comp}_{whitten}\"\n",
    "        pca = PCA(n_components=num_comp,whiten=whitten)\n",
    "        new_X = pca.fit_transform(X)\n",
    "        new_X_test = pca.transform(X_test)\n",
    "        clf = svm.SVC(kernel=\"rbf\",max_iter=5000)\n",
    "        clf.fit(new_X, y.ravel()) \n",
    "        test = clf.predict(new_X_test)\n",
    "        cm = confusion_matrix(y_test.ravel(),test,4) \n",
    "        test_res = calculate_metrics(cm)\n",
    "        print((name,test_res))\n",
    "        results.append((name,test_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Given data\n",
    "data2 = results\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data2, columns=['Model', 'Metrics'])\n",
    "df = pd.concat([df, pd.DataFrame(df['Metrics'].to_list(), columns=['accuracy', 'precision', 'recall', 'F1'])], axis=1)\n",
    "\n",
    "# Melt the DataFrame for better plotting with seaborn\n",
    "df_metrics_melted = pd.melt(df, id_vars=['Model'], value_vars=['accuracy', 'precision', 'recall', 'F1'], var_name='Metric', value_name='Value')\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Plot the bar plot for metrics\n",
    "plt.figure(figsize=(40, 12))\n",
    "ax1 = sns.barplot(x='Model', y='Value', hue='Metric', data=df_metrics_melted, palette='viridis')\n",
    "plt.title('Bar Plot for Metrics by Model (excluding Time)')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
