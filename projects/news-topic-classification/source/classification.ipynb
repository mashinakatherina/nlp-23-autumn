{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from pytorch_lightning.utilities.types import STEP_OUTPUT\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "866709bfce1891a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_embeddings = os.path.realpath(\"../assets/annotated_corpus/train_embeddings.tsv\")\n",
    "test_embeddings = os.path.realpath(\"../assets/annotated_corpus/test_embeddings.tsv\")\n",
    "topics = os.listdir(os.path.realpath(\"../assets/annotated_corpus/train\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepare_dataset(filename):\n",
    "    x_raw = []\n",
    "    y_raw = []\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            y_raw.append(topics.index(line.split(\"\\t\", 1)[0].split(\"\\\\\")[0]))\n",
    "            x_raw.append(list(map(float, line.split(\"\\t\", 1)[1].split(\"\\t\"))))\n",
    "            \n",
    "    return np.array(x_raw), np.array(y_raw)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2e3ab3b728d560e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train, y_train = prepare_dataset(train_embeddings)\n",
    "x_test, y_test = prepare_dataset(test_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9559fe9e7321a093"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf1 = SVC()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7c0c5080075d0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf1.fit(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b784bd42837f113"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = clf1.predict(x_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53cae70deec8bfba"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_raw_metrics(pred, gt):\n",
    "    metrics_dict = {}\n",
    "    if pred.shape != gt.shape:\n",
    "        raise RuntimeError(\"Shapes doesn't fit\")\n",
    "    for i in gt:\n",
    "        if i not in metrics_dict.keys():\n",
    "             metrics_dict[i] = {\"tp\": 0, \"fp\": 0, \"tn\": 0, \"fn\": 0}\n",
    "    for i in range(pred.shape[0]):\n",
    "        if pred[i] == gt[i]:\n",
    "            metrics_dict[gt[i]][\"tp\"] += 1\n",
    "            for j in metrics_dict.keys():\n",
    "                if j != gt[i]:\n",
    "                    metrics_dict[j][\"tn\"] += 1\n",
    "        else:\n",
    "            metrics_dict[pred[i]][\"fp\"] += 1\n",
    "            metrics_dict[gt[i]][\"fn\"] += 1\n",
    "    \n",
    "    return metrics_dict\n",
    "         "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa6aa5ec5ebf7c4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_metrics(pred, gt):\n",
    "    raw_dict = calculate_raw_metrics(pred, gt)\n",
    "    metrics_dict = {}\n",
    "    global_tp = 0\n",
    "    global_fp = 0\n",
    "    global_tn = 0\n",
    "    global_fn = 0\n",
    "    metrics_dict[\"precision_macro\"] = 0\n",
    "    metrics_dict[\"recall_macro\"] = 0\n",
    "    metrics_dict[\"f1_macro\"] = 0\n",
    "    for i in raw_dict.keys():\n",
    "        metrics_dict[i] = {}\n",
    "        metrics_dict[i][\"precision\"] = raw_dict[i][\"tp\"] / (raw_dict[i][\"tp\"] + raw_dict[i][\"fp\"])\n",
    "        metrics_dict[i][\"recall\"] = raw_dict[i][\"tp\"] / (raw_dict[i][\"tp\"] + raw_dict[i][\"fn\"])\n",
    "        metrics_dict[i][\"f1\"] = 2 * raw_dict[i][\"tp\"] / (2 * raw_dict[i][\"tp\"] + raw_dict[i][\"fp\"] + raw_dict[i][\"fn\"])\n",
    "        global_tp += raw_dict[i][\"tp\"]\n",
    "        global_tn += raw_dict[i][\"tn\"]\n",
    "        global_fn += raw_dict[i][\"fn\"]\n",
    "        global_fp += raw_dict[i][\"fp\"]\n",
    "        metrics_dict[\"precision_macro\"] += metrics_dict[i][\"precision\"] / len(raw_dict.keys())\n",
    "        metrics_dict[\"recall_macro\"] += metrics_dict[i][\"recall\"] / len(raw_dict.keys())\n",
    "        metrics_dict[\"f1_macro\"] += metrics_dict[i][\"f1\"] / len(raw_dict.keys())\n",
    "    metrics_dict[\"precision_micro\"] = global_tp / (global_tp + global_fp)\n",
    "    metrics_dict[\"recall_micro\"] = global_tp / (global_tp + global_fn)\n",
    "    metrics_dict[\"f1_micro\"] = 2 * global_tp / (2 * global_tp + global_fn + global_fp)\n",
    "    metrics_dict[\"accuracy\"] = global_tp / gt.shape[0]\n",
    "    return metrics_dict"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "266bb72e1ca273d2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def reference_metrics(pred, gt):\n",
    "    print(\"Precision:\", precision_score(gt, pred, average=None))\n",
    "    print(\"Recall:\", recall_score(gt, pred, average=None))\n",
    "    print(\"F1:\", f1_score(gt, pred, average=None))\n",
    "    print(\"Precision macro:\", precision_score(gt, pred, average=\"macro\"))\n",
    "    print(\"Recall macro:\", recall_score(gt, pred, average=\"macro\"))\n",
    "    print(\"F1 macro:\", f1_score(gt, pred, average=\"macro\"))\n",
    "    print(\"Precision micro:\", precision_score(gt, pred, average=\"micro\"))\n",
    "    print(\"Recall micro:\", recall_score(gt, pred, average=\"micro\"))\n",
    "    print(\"F1 micro:\", f1_score(gt, pred, average=\"micro\"))\n",
    "    print(\"Accuracy:\", accuracy_score(gt, pred))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6b8f8b8ab452c1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calculate_metrics(preds, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "874e9f74a1a86039"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reference_metrics(preds, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d18ad66726634bd4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_evaluate_model(model, x_train, y_train, x_test, y_test):\n",
    "    t_begin = time.time()\n",
    "    model.fit(x_train, y_train, )\n",
    "    t_end = time.time()\n",
    "    preds = model.predict(x_test)\n",
    "    metrics = calculate_metrics(preds, y_test)\n",
    "    print(\"Precision macro:\", metrics[\"precision_macro\"])\n",
    "    print(\"Recall macro:\", metrics[\"recall_macro\"])\n",
    "    print(\"F1 macro:\", metrics[\"f1_macro\"])\n",
    "    print(\"Precision micro:\", metrics[\"precision_micro\"])\n",
    "    print(\"Recall micro:\", metrics[\"recall_micro\"])\n",
    "    print(\"F1 micro:\", metrics[\"f1_micro\"])\n",
    "    print(\"Accuracy:\", metrics[\"accuracy\"])\n",
    "    print(\"Time:\", t_end - t_begin)\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d493b4070b57a17c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_linear = train_evaluate_model(SVC(kernel=\"linear\"), x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f31d6082213eb77"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_poly = train_evaluate_model(SVC(kernel=\"poly\"), x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9cffb2df944f3b92"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_rbf = train_evaluate_model(SVC(kernel=\"rbf\"), x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3889f2239083feb2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "svm_sigmoid = train_evaluate_model(SVC(kernel=\"sigmoid\"), x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6be8cfa6c9a79a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c4b11225b7cf2adb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MLP(pl.LightningModule):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(100, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 20),\n",
    "            torch.nn.Softmax(dim=0)\n",
    "        )\n",
    "        self.loss_func = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x = batch[:, :100]\n",
    "        y = batch[:, 100:]\n",
    "        y_hat = self.layers(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        \n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x = batch[:, :100]\n",
    "        y = batch[:, 100:]\n",
    "        y_hat = self.layers(x)\n",
    "        loss = self.loss_func(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                     lr=1e-5,\n",
    "                                     weight_decay=1e-8)\n",
    "        return optimizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ed87d8692038a27"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_train_onehot = torch.nn.functional.one_hot(torch.tensor(y_train, dtype=torch.int64))\n",
    "data = torch.cat((torch.tensor(x_train, dtype=torch.float64), y_train_onehot), dim=1).float()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "848e1256251710a9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=data, batch_size=32, shuffle=True)\n",
    "early_stop_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\")\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(monitor=\"val_loss\")\n",
    "logger = pl.loggers.TensorBoardLogger(\"tensorboard_logs/\")\n",
    "trainer = pl.Trainer(max_epochs=200, logger=logger)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2511f5b6442485c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mlp = MLP()\n",
    "trainer.fit(mlp, train_loader)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e6835339b465200a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5506b1b14841253a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "925043aa6e210834"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "preds = torch.argmax(mlp.forward(torch.tensor(x_test).float()).detach(), dim=1).numpy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c1941ea8e93ac6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "calculate_metrics(preds, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3069b204f442ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train, y_train, x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7a4ca79f91653f8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "perm = np.random.permutation(len(x_train))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c2d60b2f5993af5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:9000], y_train[perm][:9000], x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a200bc8f9cf85d06"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:6000], y_train[perm][:6000], x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a6264ed5a22e112"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[perm][:2000], y_train[perm][:2000], x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55e0227c38206914"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train[:, 10:90], y_train, x_test[:, 10:90], y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f21f50a1f5aeef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "pca.fit(x_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eae2c7eef2c62966"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), pca.transform(x_train), y_train, pca.transform(x_test), y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fe9d7a7deb30f3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pca_2 = PCA(n_components=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55d30990ba0093fd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_data = pca_2.fit_transform(x_train[perm][:500])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f9191df8225e4a1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "draw_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28c0b48efcf58d9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f5e4392676a9771"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.scatter(draw_data[:, 0], draw_data[:, 1], c=y_train[perm][:500], cmap=\"tab20\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c31685c23179e0cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_extended = np.concatenate((x_train, np.sin(x_train), np.cos(x_train)), axis=1)\n",
    "x_test_extended = np.concatenate((x_test, np.sin(x_test), np.cos(x_test)), axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "78e8449cabae1238"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train_extended.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d95836e94623574d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_evaluate_model(SVC(kernel=\"rbf\"), x_train_extended, y_train, x_test_extended, y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5141dc5c5282dc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
